---
title: "main"
output: html_document
date: "2022-11-20"
author: "Jonas Barth, Mattia Castaldo, Matteo Migliarini"
---

# 2. Differential Privacy

# 2.1 Univariate Differential Privacy

Index

-   [Requirements](#requirements)
-   [Original and Perturbed Histogram Example](#original-and-perturbed-histogram-example)
-   [Simulation](#simulation)
-   [Plotting](#plotting)

## Requirements {#requirements}

```{r}
require('VGAM') # for sampling from a laplace
require("dplyr") # for using group by on the data from the simulation
require("colorspace") # for plotting
require("latex2exp") # for mathematical expressions in plots
```

## Original and Perturbed Histogram Example {#original-and-perturbed-histogram-example}

To get a visual understanding of what it means to perturbe a histogram, we will show an original histogram sampled from a $Beta$ distribution and its perturbed version.

### Hyperparameters

```{r}
n = 1000
eps = 0.1
m = n^(1 / (2 + 1))
```

### Original Histogram

The original histogram is sampled from a $Beta$ distribution with $\alpha = 10, \beta = 10$.

```{r echo=FALSE}
b_sample = rbeta(n=n, 10, 10)

original_hist = hist(b_sample, plot=F, breaks=m-1)

plot(original_hist,
     xlab = NULL,
     ylab = NULL,
     col='red',
     border='white',
     main = paste("Histogram of", n ,"samples from a Beta(10, 10) distribution"))
```

### Perturbed Histogram

Since we have to create many perturbed histograms, we will put this logic into a function for reusability.

```{r}
l_perturbe = function(h, variance = 8 / (0.001 ^ 2)) {
    perturbed_hist = h
    lap_sample = rlaplace(length(perturbed_hist$counts), scale = sqrt(variance/2))
    
    # Add the laplace sample to D_j
    perturbed_hist$counts = perturbed_hist$counts + lap_sample
    
    # If we end up with a negative number, we choose 0 instead. Same as max(0, D_j)
    perturbed_hist$counts[perturbed_hist$counts <= 0] = 0
    
    # If our samples from the laplace lead to a negative count in each bin, we cannot normalise over the
    # sum since this would be a division over 0.
    if (any(is.na(perturbed_hist$counts))) {
        perturbed_hist$counts = rep(0, length(perturbed_hist$counts))
    } else {
        # Normalise D_j over the sum of all bins
        perturbed_hist$counts = perturbed_hist$counts / sum(perturbed_hist$counts)
    }

    # Also update the density, divide q_hat by 1/m
    perturbed_hist$density = perturbed_hist$counts / (1 / m)
    
    return(perturbed_hist)
}
```

Plot the peturbed histogram. We can see that it is more sparse than the original histogram.

```{r echo=FALSE}
perturbed_hist = l_perturbe(original_hist, variance = 8 / (eps^2))
plot(original_hist, 
     freq=F, 
     main='Perturbed Histogram vs Original',
     col=rgb(1,0,0),
     border='white')
plot(perturbed_hist,
     freq=F,
     add=T, col=rgb(0,0,1,0.5),border='white')
legend('topright',
       legend=c('Original', 'Perturbed', ' Intersection'),
       col=c(rgb(1,0,0), rgb(0,0,1,0.5), rgb(.5,0,1)),
       lwd = 10
)
```

## Simulation {#simulation}

Now we can get to the actual simulation of the $MISE$ between the original distribution and original histogram, and the $MISE$ between the original distribution and the perturbed histogram.

### Hyperparameters

These are the hyperparameters needed for the simulation.

```{r}
n_values = c(100,1000) # sample size
eps_values = c(0.1, 0.001) # values for epsilon
bins_values = seq(5, 50, 5) # values for the histogram bin size
M = 1000 # number of simulations to be run
```

### Function for running simulations with fixed hyperparameters

At each simulation, we do the following:

1.  Sample from the beta distribution.
2.  Create a histogram from the sample.
3.  Perturb the histogram.
4.  Calculate the $MISE(p_X, \hat{p}_{n, m})$.
5.  Calculate the $MISE(p_X, \hat{q}_{\epsilon, m})$.
6.  Save the $MISE$ values and hyperparameters of this simulation run into a dataframe.

```{r}
mise_sim = function(n, n_bins, eps, sim_size, dist=function(n) rbeta(n, 10, 10)) {
    
    out = data.frame()
    
    for (m in 1:sim_size) {

        # 1. sample from beta
        b_sample = dist(n=n)

        # 2. create original hist
        original_hist = hist(b_sample, plot=F, breaks=n_bins - 1)
        
        d_original = stepfun(original_hist$breaks, c(0, original_hist$density, 0))

        # 3. create perturbed hist
        perturbed_hist = l_perturbe(original_hist, variance = 8 / (eps^2))
        
        d_perturbed = stepfun(perturbed_hist$breaks, c(0, perturbed_hist$density, 0))
        
        # 4. calculate mise original
        mise_original = integrate(function(x) (dbeta(x, 10, 10) - d_original(x))^2, 0, 1, subdivisions = 1000)$value

        # 5. calculate mise perturbed
        mise_perturbed = integrate(function(x) (dbeta(x, 10, 10) - d_perturbed(x))^2, 0, 1, subdivisions = 1000)$value
        
        # 6. save the MISE values and hyperparameters
        out = rbind(out, data.frame(m=m, n=n, eps=eps, bins=n_bins, mise_original=mise_original, mise_perturbed=mise_perturbed))
    }
    
    return(out)
}

```

### Running the Simulation

We run the simulation $M$ times for all possible hyperparameter combinations. The results are saved into a dataframe.

```{r}
sim_data = data.frame()

# Create a grid with all possible hyperparameter combinations
hyperparameter_grid = expand.grid(n = n_values, bins = bins_values, eps = eps_values)

for(rowname in rownames(hyperparameter_grid)) {
    n = hyperparameter_grid[rowname, "n"]
    bins = hyperparameter_grid[rowname, "bins"]
    eps = hyperparameter_grid[rowname, "eps"]
    
    sim_result = mise_sim(n = n, n_bins = bins, eps = eps, sim_size = M)
    sim_data = rbind(sim_data, sim_result)
}
```

```{r}
sim_data
```

## Plotting {#plotting}

### Absolute MISE Differences

We want to show how the absolute difference between the two calculated $MISE$ values varies across the different combinations of hyper parameters.

#### Preparing Data for Plotting

There are 3 steps in the data preparation process:

1.  Calculate the absolute difference between the two $MISE$ values.
2.  Group the data by epsilon value, sample size (n), and number of bins.
3.  Get a subset for each possible (sample size, epsilon) pair. Four in total.

```{r}

# 2. group data
mise_data_group <- sim_data %>%
  group_by(eps, n, bins) %>%
  dplyr::summarize(mise_original_mean = mean(mise_original),
                   mise_original_min = min(mise_original),
                   mise_original_max = max(mise_original),
                   mise_perturbed_mean = mean(mise_perturbed),
                   mise_perturbed_min = min(mise_perturbed),
                   mise_perturbed_max = max(mise_perturbed)) %>% 
  as.data.frame()
```

#### Parameters for plotting

```{r}
colours = rainbow_hcl(2)
lwd = 4
legend_names = c("n = 100, eps = 0.1", "n = 100, eps = 0.001", "n = 1000, eps = 0.1", "n = 1000, eps = 0.001")
```

### Original Mise Variation

In the 4 plots below we see the average: \* MISE value for the original histogram. \* MISE value for the perturbed histogram. \* Absolute difference between the MISE for the original histogram and MISE for the perturbed histogram.

#### Function for a single plot

This function plots a line plot with three lines: \* mean of the original MISE \* mean of the perturbed MISE \* mean of the MISE difference

```{r}
plot_mise_values = function(mise_data, main, sub, colours, lwd = 3) {
  
  max_y = max(c(mise_data$mise_original_mean, mise_data$mise_perturbed_mean))
  plot(NULL,
     xlim = c(min(bins_values), max(bins_values)),
     ylim = c(0, max_y),
     ylab = "MISE",
     xlab = "Number of bins",
     main = main,
     sub = sub)
  lines(mise_data$bins, mise_data$mise_original_mean, type = "l", lwd = lwd, col = colours[1])
  lines(mise_data$bins, mise_data$mise_perturbed_mean, type = "l", lwd = lwd, col = colours[2])
}
```

#### Plotting
The 4 plots below show the:
* original $MISE$
* perturbed $MISE$

for the 4 combinations of the sample sizes $n \: \in \: \{100, 1000}$ and the epsilon values $\epsilon \: \in \{0.001, 0.1\}$.

For a small privacy ratio $\epsilon = 0.001$, we can see that the $MISE$ of the perturbed histogram initially has a higher value that for a privacy ratio of $\epsilon = 0.1$. Also, a larger the sample size $n$ for the perturbed $MISE$ also corresponds to a higher initial $MISE$ when comparing values that have the same value for $\epsilon$. E.g. For $\epsilon = 0.001$, the perturbed $MISE$ for the sample size $n = 100$ starts at around $6$, whereas the perturbed $MISE$ for the sample size $n = 1000$ starts at around $10$. For small sample sizes $n = 100$, both the original $MISE$ starts off close to $0$, however with an increase in the number of bins, it approaches $1$.

One thing that is common across all 4 plots is that there is a decrease in the perturbed $MISE$ when moving from $5$ to $10$ bins. For $MISE$ that have $\epsilon = 0.1$, this initial decrease is then followed by a steady increase.

```{r}

plot_n_eps = function(mise_data) {
  line_colours = rainbow_hcl(2)

  mise_data_1 = subset(mise_data, mise_data$n == 100 & mise_data$eps == 0.1)
  mise_data_2 = subset(mise_data, mise_data$n == 100 & mise_data$eps == 0.001)
  mise_data_3 = subset(mise_data, mise_data$n == 1000 & mise_data$eps == 0.1)
  mise_data_4 = subset(mise_data, mise_data$n == 1000 & mise_data$eps == 0.001)

  # Create a layout for the 4 plots and the common legend
  layout(matrix(c(1,2,5,3,4,5), ncol=2, nrow=3), heights=c(6, 6, 2))

  # Plot the 4 plots
  plot_mise_values(mise_data_1, paste("MISE values over", M, "Simulations."), "n = 100, eps = 0.1.", line_colours)
  plot_mise_values(mise_data_2, paste("MISE values over", M, "Simulations."), "n = 100, eps = 0.001.", line_colours)
  plot_mise_values(mise_data_3, paste("MISE values over", M, "Simulations."), "n = 1000, eps = 0.1", line_colours)
  plot_mise_values(mise_data_4, paste("MISE values over", M, "Simulations."), "n = 1000, eps = 0.001.", line_colours)

  # Plot the legend
  par(mai=c(0,0,0,0))
  plot.new()
  legend("center",
         legend = c(TeX("$MISE(p_X, \\hat{p}_{n,m})$"), TeX("$MISE(p_X, \\hat{q}_{\\epsilon, m})$")),
         col = colours,
         lwd = 3,
         xpd = TRUE,
         horiz = TRUE,
         cex = 1,
         seg.len=2)
}

plot_n_eps(mise_data_group)

```

# 2.2 Sampling from a different distribution

We now sample from: $$
p_X(x) = \pi \cdot \text{dbeta}(x | \alpha_1, \beta_1) + (1 -\pi )\cdot \text{dbeta}(x | \alpha_2, \beta_2)
$$

```{r}
func = function(n, pi =.5) pi * rbeta(n,.5,.3) + (1 - pi) * rbeta(n,.5,.1)
h=hist(func(1000), plot=F)
plot(h, main='Density of
     p[X]',xlab = '', freq=F)
```

## Perturbed Histogram

```{r echo=FALSE}
h_perturbed=l_perturbe(h)

plot(h, 
     freq=F, 
     main='Perturbed Histogram vs Original',
     col=rgb(1,0,0),
     border='white', xlab='')
plot(h_perturbed,
     freq=F,
     add=T, col=rgb(0,0,1,0.5),border='white')
legend('topright',
       legend=c('Original', 'Perturbed', ' Intersection'),
       col=c(rgb(1,0,0), rgb(0,0,1,0.5), rgb(.5,0,1)),
       lwd = 10)
```

## Run Simulation

We will run the simulation with the same parameters for $n$, $\epsilon$ and $m$ and for the same number of times $M$. We also have $\pi \; \epsilon \; \{0.25, 0.5, 0.75\}$ as an additional parameter.

```{r}
pi_values = c(.25,.5,.75)
out_new = data.frame()

hyperparameter_grid = expand.grid(n = n_values, bins = bins_values, eps = eps_values, pi = pi_values)

for (n in n_values) {
    for (eps in eps_values) {
        for (n_bins in bins_values) {
            for (pi in pi_values)   {
                sim_result = mise_sim(n, n_bins, eps, sim_size = M, dist=func)
                sim_result$pi = pi
                out_new = rbind(out_new, sim_result)
            }
        }
    }
}
```

## Plotting

Like in the plots for question 2.1, we will show how the two calculated $MISE$ values vary across the different combinations of hyper parameters.


### Group Data
First, we group the data, however this time we also group on $\pi$ in addition to the other parameters.

```{r}
# 2. group data
mise_data_group_pi <- out_new %>%
  group_by(eps, n, bins, pi) %>%
  dplyr::summarize(mise_original_mean = mean(mise_original),
                   mise_original_min = min(mise_original),
                   mise_original_max = max(mise_original),
                   mise_perturbed_mean = mean(mise_perturbed),
                   mise_perturbed_min = min(mise_perturbed),
                   mise_perturbed_max = max(mise_perturbed)) %>% 
  as.data.frame()
```

### Subset Data

Finally, we create one subset of the data for each value of $\pi$. We do this because splitting the data across three plots, each with their own $\pi$, makes the visualisation more readable.

```{r}
pi_025 = subset(mise_data_group_pi, mise_data_group_pi$pi == 0.25)
pi_05 = subset(mise_data_group_pi, mise_data_group_pi$pi == 0.5)
pi_075 = subset(mise_data_group_pi, mise_data_group_pi$pi == 0.75)
```

### Function to Plot Original and Perturbed MISE.
```{r}
plot_multiple_mise = function(mise_data, main_title, pi) {
  line_colours = rainbow_hcl(2)

  mise_data_1 = subset(mise_data, mise_data$n == 100 & mise_data$eps == 0.1)
  mise_data_2 = subset(mise_data, mise_data$n == 100 & mise_data$eps == 0.001)
  mise_data_3 = subset(mise_data, mise_data$n == 1000 & mise_data$eps == 0.1)
  mise_data_4 = subset(mise_data, mise_data$n == 1000 & mise_data$eps == 0.001)

  # Create a layout for the 4 plots and the common legend
  layout(matrix(c(1,2,5,3,4,5), ncol=2, nrow=3), heights=c(6, 6, 2))

  # Plot the 4 plots
  plot_mise_values(mise_data_1, main = main_title, paste("n = 100, eps = 0.1, pi = ", pi), line_colours)
  plot_mise_values(mise_data_2, main = main_title, paste("n = 100, eps = 0.001, pi = ", pi), line_colours)
  plot_mise_values(mise_data_3, main = main_title, paste("n = 1000, eps = 0.1, pi = ", pi), line_colours)
  plot_mise_values(mise_data_4, main = main_title, paste("n = 1000, eps = 0.001, pi = ", pi), line_colours)

    # Plot the legend
  par(mai=c(0,0,0,0))
  plot.new()
  legend("center",
         legend = c(TeX("$MISE(p_X, \\hat{p}_{n,m})$"), TeX("$MISE(p_X, \\hat{q}_{\\epsilon, m})$")),
         col = line_colours,
         lwd = 3,
         xpd = TRUE,
         horiz = TRUE,
         cex = 1,
         seg.len=2)
}
```

### Plot pi = 0.25.
```{r}
plot_multiple_mise(pi_025, paste("MISE values over", M, "Simulations."), pi = 0.25)
```
### Plot pi = 0.5.
```{r}
plot_multiple_mise(pi_05, paste("MISE values over", M, "Simulations."), pi = 0.5)
```
### Plot pi = 0.75.
```{r}
plot_multiple_mise(pi_075, paste("MISE values over", M, "Simulations."), pi = 0.75)
```
## 2.4 Bonus
We want to perform some simulations to test whether our mechanism ensures $\epsilon$ differential privacy:
```{r}
n.sim = 100
ratio = numeric(n.sim)
eps = .1

for (i in 1:n.sim) {
  h = hist(rbeta(1e5,10,10), breaks=floor(1e5^(1/3)),plot=F)
  h$density = h$density/2
  h_p = l_perturbe(h,variance=8/eps^2)

  diff = max( h$density[h_p$density!=0]/h_p$density[h_p$density!=0] )
  #plot(h, freq=F, c=rgb(1,0,0))
  #plot(h_p, freq=F, add=T, c= rgb(0,1,0,0.5))
  ratio[i] = diff
}
sum(ratio <= exp(eps)) / n.sim
```
#### TODO : for some reasone it appears that differential privacy isn't always ensured?