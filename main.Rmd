---
title: "main"
output: html_document
date: "2022-11-20"
author: "Jonas Barth, Mattia Castaldo, Matteo Migliarino"
---

# 2. Differential Privacy

# 2.1 Univariate Differential Privacy

Index

-   [Requirements](#requirements)
-   [Original and Perturbed Histogram Example](#original-and-perturbed-histogram-example)
-   [Simulation](#simulation)
-   [Plotting](#plotting)

## Requirements {#requirements}

```{r}
require('VGAM') # for sampling from a laplace
require("dplyr") # for using group by on the data from the simulation
require("colorspace") # for plotting
require("latex2exp") # for mathematical expressions in plots
```

## Original and Perturbed Histogram Example {#original-and-perturbed-histogram-example}

To get a visual understanding of what it means to perturbe a histogram, we will show an original histogram sampled from a $Beta$ distribution and its perturbed version.

### Hyperparameters

```{r}
n = 1000
eps = 0.1
m = n^(1 / (2 + 1))
```

### Original Histogram

The original histogram is sampled from a $Beta$ distribution with $\alpha = 10, \beta = 10$.

```{r}
b_sample = rbeta(n=n, 10, 10)

original_hist = hist(b_sample, plot=F, breaks=m-1)

plot(original_hist,
     xlab = NULL,
     ylab = NULL,
     main = paste("Histogram of", n ,"samples from a Beta(10, 10) distribution"))
```

### Perturbed Histogram

Since we have to create many perturbed histograms, we will put this logic into a function for reusability.

```{r}
l_perturbe = function(h, variance = 8 / (0.001 ^ 2)) {
    perturbed_hist = h
    lap_sample = rlaplace(length(perturbed_hist$counts), scale = sqrt(variance/2))
    
    # Add the laplace sample to D_j
    perturbed_hist$counts = perturbed_hist$counts + lap_sample
    
    # If we end up with a negative number, we choose 0 instead. Same as max(0, D_j)
    perturbed_hist$counts[perturbed_hist$counts <= 0] = 0
    
    # If our samples from the laplace lead to a negative count in each bin, we cannot normalise over the
    # sum since this would be a division over 0.
    if (any(is.na(perturbed_hist$counts))) {
        perturbed_hist$counts = rep(0, length(perturbed_hist$counts))
    } else {
        # Normalise D_j over the sum of all bins
        perturbed_hist$counts = perturbed_hist$counts / sum(perturbed_hist$counts)
    }

    # Also update the density, divide q_hat by 1/m
    perturbed_hist$density = perturbed_hist$counts / (1 / m)
    
    return(perturbed_hist)
}
```

Plot the peturbed histogram. We can see that it is more sparse than the original histogram.

```{r}
perturbed_hist = l_perturbe(original_hist, variance = 8 / (eps^2))
plot(perturbed_hist, 
     freq=F, 
     main='Perturbed Hihstogram')
```

## Simulation {#simulation}

Now we can get to the actual simulation of the $MISE$ between the original distribution and original histogram, and the $MISE$ between the original distribution and the perturbed histogram.

### Hyperparameters

These are the hyperparameters needed for the simulation.

```{r}
n_values = c(100,1000) # sample size
eps_values = c(0.1, 0.001) # values for epsilon
bins_values = seq(5, 50, 5) # values for the histogram bin size
M = 1000 # number of simulations to be run
```

### Function for running simulations with fixed hyperparameters

At each simulation, we do the following:

1.  Sample from the beta distribution.
2.  Create a histogram from the sample.
3.  Perturb the histogram.
4.  Calculate the $MISE(p_X, \hat{p}_{n, m})$.
5.  Calculate the $MISE(p_X, \hat{q}_{\epsilon, m})$.
6.  Save the $MISE$ values and hyperparameters of this simulation run into a dataframe.

```{r}
mise_sim = function(n, n_bins, eps, sim_size, dist=function(n) rbeta(n, 10, 10)) {
    
    out = data.frame()
    
    for (m in 1:sim_size) {

        # 1. sample from beta
        b_sample = dist(n=n)

        # 2. create original hist
        original_hist = hist(b_sample, plot=F, breaks=n_bins - 1)
        
        d_original = stepfun(original_hist$breaks, c(0, original_hist$density, 0))

        # 3. create perturbed hist
        perturbed_hist = l_perturbe(original_hist, variance = 8 / (eps^2))
        
        d_perturbed = stepfun(perturbed_hist$breaks, c(0, perturbed_hist$density, 0))
        
        # 4. calculate mise original
        mise_original = integrate(function(x) (dbeta(x, 10, 10) - d_original(x))^2, 0, 1, subdivisions = 1000)$value

        # 5. calculate mise perturbed
        mise_perturbed = integrate(function(x) (dbeta(x, 10, 10) - d_perturbed(x))^2, 0, 1, subdivisions = 1000)$value
        
        # 6. save the MISE values and hyperparameters
        out = rbind(out, data.frame(m=m, n=n, eps=eps, bins=n_bins, mise_original=mise_original, mise_perturbed=mise_perturbed))
    }
    
    return(out)
}

```

### Running the Simulation

We run the simulation $M$ times for all possible hyperparameter combinations. The results are saved into a dataframe.

```{r}
sim_data = data.frame()

# Create a grid with all possible hyperparameter combinations
hyperparameter_grid = expand.grid(n = n_values, bins = bins_values, eps = eps_values)

for(rowname in rownames(hyperparameter_grid)) {
    n = hyperparameter_grid[rowname, "n"]
    bins = hyperparameter_grid[rowname, "bins"]
    eps = hyperparameter_grid[rowname, "eps"]
    
    sim_result = mise_sim(n = n, n_bins = bins, eps = eps, sim_size = M)
    sim_data = rbind(sim_data, sim_result)
}
```

```{r}
sim_data
```

## Plotting {#plotting}

### Absolute MISE Differences

We want to show how the absolute difference between the two calculated $MISE$ values varies across the different combinations of hyper parameters.

#### Preparing Data for Plotting

There are 3 steps in the data preparation process:

1.  Calculate the absolute difference between the two $MISE$ values.
2.  Group the data by epsilon value, sample size (n), and number of bins.
3.  Get a subset for each possible (sample size, epsilon) pair. Four in total.

```{r}

# 1. absolute difference
sim_data$mise_diff = abs(sim_data$mise_original - sim_data$mise_perturbed)

# 2. group data
data_group <- sim_data %>%                                 
  group_by(eps, n, bins) %>%
  dplyr::summarize(mise_diff_mean = mean(mise_diff), 
                   mise_diff_min = min(mise_diff), 
                   mise_diff_max = max(mise_diff),
                   mise_original_mean = mean(mise_original),
                   mise_original_min = min(mise_original),
                   mise_original_max = max(mise_original),
                   mise_perturbed_mean = mean(mise_perturbed),
                   mise_perturbed_min = min(mise_perturbed),
                   mise_perturbed_max = max(mise_perturbed)) %>% 
  as.data.frame()

# 3. Get subsets.
data1 = subset(data_group, data_group$n == 100 & data_group$eps == 0.1)
data2 = subset(data_group, data_group$n == 100 & data_group$eps == 0.001)
data3 = subset(data_group, data_group$n == 1000 & data_group$eps == 0.1)
data4 = subset(data_group, data_group$n == 1000 & data_group$eps == 0.001)
```

#### Parameters for plotting

```{r}
colours = rainbow_hcl(4)
lwd = 4
legend_names = c("n = 100, eps = 0.1", "n = 100, eps = 0.001", "n = 1000, eps = 0.1", "n = 1000, eps = 0.001")
```

#### Plot for MISE Differences

The plot below shows the absolute differences between the MISE value for the original histogram and the MISE value for the perturbed histogram.

$$|MISE(p_X, \hat{p}_{n,m}) - MISE(p_X, \hat{q}_{\epsilon, m})|$$

Each line in the plot represents the absolute MISE difference for a specific combination of the number of samples from the Beta distribution $n$ and the privacy value epsilon $\epsilon$, averaged over $M$ simulations.

From the plot we can see that, as the number of bins increase, the MISE difference convergence seems to happen independently of the value for epsilon. For the smaller sample size $n = 100$, this happens around a number of bins $m = 25$. For the larger sample size $n = 1000$, this happens earlier around the number of bins $m = 10$.

This could be explained by the fact that smaller sample sizes are less likely to capture the necessary variance which is more likely to result in a skewed histogram when it has few bins.

```{r}
plot_n_eps = function(mise_data) {
  mise_data_1 = subset(mise_data, mise_data$n == 100 & mise_data$eps == 0.)
  mise_data_2 = subset(mise_data, mise_data$n == 100 & mise_data$eps == 0.001)
  mise_data_3 = subset(mise_data, mise_data$n == 1000 & mise_data$eps == 0.1)
  mise_data_4 = subset(mise_data, mise_data$n == 1000 & mise_data$eps == 0.001)
  
  plot(NULL,
       xlim = c(min(bins_values), max(bins_values)),
       ylim = c(min(mise_data$mise_diff_mean), max(mise_data$mise_diff_mean)),
       ylab = "Mean MISE Differences",
       xlab = "Number of bins",
       main = paste("Mean MISE differences over", M, "simulations"))
  lines(mise_data_1$bins, mise_data_1$mise_diff_mean, type = "l", lwd = lwd, col = colours[1])
  lines(mise_data_2$bins, mise_data_2$mise_diff_mean, type = "l", lwd = lwd, col = colours[2])
  lines(mise_data_3$bins, mise_data_3$mise_diff_mean, type = "l", lwd = lwd, col = colours[3])
  lines(mise_data_4$bins, mise_data_4$mise_diff_mean, type = "l", lwd = lwd, col = colours[4])
  legend("topright", 
         legend=legend_names,
         col = colours,
         lwd = lwd)
}
plot_n_eps(data_group)
```

### Original Mise Variation

In the 4 plots below we see the average: \* MISE value for the original histogram. \* MISE value for the perturbed histogram. \* Absolute difference between the MISE for the original histogram and MISE for the perturbed histogram.

#### Function for a single plot

This function plots a line plot with three lines: \* mean of the original MISE \* mean of the merturbed MISE \* mean of the MISE difference

```{r}
plot_mise_values = function(mise_data, main, sub, colours, lwd = 3) {
  
  max_y = max(c(mise_data$mise_original_mean, mise_data$mise_perturbed_mean, mise_data$mise_diff_mean))
  plot(NULL,
     xlim = c(min(bins_values), max(bins_values)),
     ylim = c(0, max_y),
     ylab = "MISE",
     xlab = "Number of bins",
     main = main,
     sub = sub)
  lines(mise_data$bins, mise_data$mise_original_mean, type = "l", lwd = lwd, col = colours[1])
  lines(mise_data$bins, mise_data$mise_perturbed_mean, type = "l", lwd = lwd, col = colours[2])
  lines(mise_data$bins, mise_data$mise_diff_mean, type = "l", lwd = lwd, col = colours[3])
}
```

#### Plotting

The absolute differences shown in the 4 plots correspond to the lines in the previous plot. By also plotting the MISE values for the original and perturbed histogram, we can compare them easier than if we had just plotted the absolute difference. For example, for a sample size $n = 1000$, we can see that the original MISE is close to $0$ whereas the MISE of the perturbed stabilises around $2$.

```{r}
line_colours = rainbow_hcl(3)

# Create a layout for the 4 plots and the common legend
layout(matrix(c(1,2,5,3,4,5), ncol=2, nrow=3), heights=c(6, 6, 2))

# Plot the 4 plots
plot_mise_values(data1, paste("MISE values over", M, "Simulations."), "n = 100, eps = 0.1.", line_colours)
plot_mise_values(data2, paste("MISE values over", M, "Simulations."), "n = 100, eps = 0.001.", line_colours)
plot_mise_values(data3, paste("MISE values over", M, "Simulations."), "n = 1000, eps = 0.1", line_colours)
plot_mise_values(data4, paste("MISE values over", M, "Simulations."), "n = 1000, eps = 0.001.", line_colours)

# Plot the legend
par(mai=c(0,0,0,0))
plot.new()
legend("center",
       legend = c(TeX("$MISE(p_X, \\hat{p}_{n,m})$"), TeX("$MISE(p_X, \\hat{q}_{\\epsilon, m})$"), TeX("$|(MISE(p_X, \\hat{p}_{n,m}) - MISE(p_X, \\hat{q}_{\\epsilon, m})|$")),
       col = colours,
       lwd = 3, 
       xpd = TRUE, 
       horiz = TRUE, 
       cex = 1, 
       seg.len=2)

```

# 2.2 Sampling from a different distribution

We now sample from: $$
p_X(x) = \pi \cdot \text{dbeta}(x | \alpha_1, \beta_1) + (1 -\pi )\cdot \text{dbeta}(x | \alpha_2, \beta_2)
$$

```{r}
func = function(n, pi =.5) pi * rbeta(n,.5,.3) + (1 - pi) * rbeta(n,.5,.1)
h=hist(func(1000), plot=F)
plot(h, main='Density of
     p[X]',xlab = '', freq=F)
```

## Perturbed Histogram

```{r}
h_perturbed=l_perturbe(h)

plot(h_perturbed, main='Perturbed Histogram of p[X]', xlab='', freq=F)
```

## Run Simulation

We will run the simulation with the same parameters for $n$, $\epsilon$ and $m$ and for the same number of times $M$. We also have $\pi \; \epsilon \; \{0.25, 0.5, 0.75\}$ as an additional parameter.

```{r}
pi_values = c(.25,.5,.75)
out_new = data.frame()

hyperparameter_grid = expand.grid(n = n_values, bins = bins_values, eps = eps_values, pi = pi_values)

for (n in n_values) {
    for (eps in eps_values) {
        for (n_bins in bins_values) {
            for (pi in pi_values)   {
                sim_result = mise_sim(n, n_bins, eps, sim_size = M, dist=func)
                sim_result$pi = pi
                out_new = rbind(out_new, sim_result)
            }
        }
    }
}
```

## Plotting

Like in the plots for question 2.1, we will show how the absolute difference between the two calculated $MISE$ values varies across the different combinations of hyper parameters.

### MISE Difference

First, we calculate the absolute difference between the original and perturbed $MISE$.

```{r}
out_new$mise_diff = abs(out_new$mise_original - out_new$mise_perturbed)
```

### Group Data

Then, we group the data, however this time we also group on $\pi$ in addition to the other parameters.

```{r}
out_new
# 2. group data
data_group_pi <- out_new %>%                                 
  group_by(eps, n, bins, pi) %>%
  dplyr::summarize(mise_diff_mean = mean(mise_diff), 
                   mise_diff_min = min(mise_diff), 
                   mise_diff_max = max(mise_diff),
                   mise_original_mean = mean(mise_original),
                   mise_original_min = min(mise_original),
                   mise_original_max = max(mise_original),
                   mise_perturbed_mean = mean(mise_perturbed),
                   mise_perturbed_min = min(mise_perturbed),
                   mise_perturbed_max = max(mise_perturbed)) %>% 
  as.data.frame()

data_group_pi
```

### Subset Data

Finally, we create one subset of the data for each value of $\pi$. We do this because splitting the data across three plots, each with their own $\pi$, makes the visualisation more readable.

```{r}
pi_025 = subset(data_group_pi, data_group_pi$pi == 0.25)
pi_05 = subset(data_group_pi, data_group_pi$pi == 0.5)
pi_075 = subset(data_group_pi, data_group_pi$pi == 0.75)
```

### Plot

```{r}
layout(matrix(c(1, 2, 3), ncol=1, nrow=3), heights=c(10, 10, 10), TRUE) 
plot_n_eps(pi_025)
plot_n_eps(pi_05)
plot_n_eps(pi_075)
```

## 2.4 Bonus
We want to perform some simulations to test whether our mechanism ensures $\epsilon$ differential privacy:
```{r}
n.sim = 100
ratio = numeric(n.sim)
eps = .1

for (i in 1:n.sim) {
  h = hist(rbeta(100000,10,10), breaks=10,plot=F)
  h$density = h$density/2
  h_p = l_perturbe(h,variance=8/eps^2)
  
  diff = max( h$density[h_p$density!=0]/h_p$density[h_p$density!=0] )
  #plot(h, freq=F, c=rgb(1,0,0))
  #plot(h_p, freq=F, add=T, c= rgb(0,1,0,0.5))
  ratio[i] = diff
}
sum(ratio <= exp(eps)) / n.sim
```
#### TODO : for some reasone it appears that differential privacy isn't always ensured?